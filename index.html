<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="author" content="Simon Schug">
  <title>Models of Decision Making for Neuroscience</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="./reveal.js/dist/reset.css">
  <link rel="stylesheet" href="./reveal.js/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
  </style>
  <link rel="stylesheet" href="./reveal.js/dist/theme/robolung.css" id="theme">
</head>
<body>
<div class="line top"></div>
<div class="line bottom"></div>
<div class="line left"></div>
<div class="line right"></div>
  <div class="reveal">
    <div class="slides">

<section id="title-slide">
  <h1 class="title"><a href="">Models of Decision Making for Neuroscience</a></h1>
  <p class="author">Simon Schug</p>
  <p class="date">October 2020</p>
</section>

<section>
<section id="normative-models" class="title-slide slide level1" data-background="#7BAB8B">
<h1 data-background="#7BAB8B">Normative Models</h1>

</section>
<section id="uncertainty" class="slide level2">
<h2>Uncertainty</h2>
<p>The world is riddled with uncertainty.</p>
<div class="columns">
<div class="column" style="width:33%;">
<p><img src="./assets/white-noise.jpg" alt="white-noise" height="300" style="display:block;margin-left:auto;margin-right: auto;"/> <strong>Noise</strong></p>
</div><div class="column" style="width:33%;">
<!-- <iframe width="500" height="300" src="https://www.youtube.com/embed/sKa0eaKsdA0" frameborder="0"></iframe> -->
<!-- <img src="./assets/spinning-dancer.gif" alt="spinning-dance" height="300" style="display:block;margin-left:auto;margin-right: auto;"/> -->
<p><img src="./assets/rotating-mask.gif" alt="rotating-mask" height="300" style="display:block;margin-left:auto;margin-right: auto;"/> <strong>Ambiguity</strong></p>
</div><div class="column" style="width:33%;">
<p><img src="./assets/aperture-problem.gif" alt="aperture-problem" height="300" style="display:block;margin-left:auto;margin-right: auto;"/> <strong>Partial Information</strong></p>
</div>
</div>
<aside class="notes">
<ul>
<li>Why do we see a convex face when the mask turns?</li>
<li>In which direction do the bars move? Why do we see this movement in particular and not one of the other possibilities?</li>
</ul>
</aside>
</section>
<section id="probability-theory" class="slide level2">
<h2>Probability Theory</h2>
<blockquote>
<p><em>Probability theory is nothing but common sense reduced to calculation.</em></p>
</blockquote>
<div style="text-align: right">
Pierre-Simon Laplace (1819)
</div>
</section>
<section id="bayes-theorem" class="slide level2">
<h2>Bayes’ Theorem</h2>
<!-- Given an explanation $\mathcal{H}$ and observations $y$, we can compute: -->
<p>Given the state <span class="math inline">\(x\)</span>, the observation <span class="math inline">\(y\)</span> and the hypothesis space <span class="math inline">\(\mathcal{H}\)</span></p>
<p><span class="math display">\[ P(x|y, \mathcal{H}) = \frac{P(y|x, \mathcal{H}) \cdot P(x| \mathcal{H})}{P(y| \mathcal{H})} \]</span></p>
<ul>
<li><strong>Likelihood</strong>: Probability of the observations given the explanation.</li>
<li><strong>Prior</strong>: Probability of the explanation based on prior experiences.</li>
<li><strong>Posterior</strong>: Probability of the explanation given the observations.</li>
</ul>
</section>
<section id="posterior-update" class="slide level2">
<h2>Posterior Update</h2>
<p><img src="./assets/posterior-update.svg" alt="posterior-update" width="100%"/></p>
</section>
<section id="model-selection" class="slide level2">
<h2>Model Selection</h2>
<p>What happens when we have multiple explanations <span class="math inline">\(\mathcal{H}_1, \mathcal{H}_2\)</span> for the data? <span class="math display">\[\mathcal{H}^* = arg \max_{\mathcal{H}_i} P(\mathcal{H}_i|y)\]</span></p>
<ul>
<li>Find the most probable explanation by maximisation</li>
<li>Automatically embodies <a href="https://en.wikipedia.org/wiki/Occam%27s_razor">Occams’ Razor</a></li>
</ul>
<aside class="notes">
<ul>
<li>I give you two different models <span class="math inline">\(m_1\)</span> and <span class="math inline">\(m_2\)</span>.</li>
<li><span class="math inline">\(m_1\)</span> has many parameters and is thus very flexible, whereas <span class="math inline">\(m_2\)</span> is a simple model.</li>
<li>Both can explain the data equally well.</li>
<li>Which one should I choose?</li>
<li>Occams’ Razor: Choose the simplest explanation compatible with the observations.</li>
<li>Complex explanations must spread their probability mass more thinly</li>
</ul>
</aside>
</section>
<section id="how-does-bayesian-inference-help-us-to-study-decision-making" class="slide level2">
<h2>How does Bayesian inference help us to study decision making?</h2>
<aside class="notes">
<p>We have seen how probability theory can be used to represent and updates our beliefs about the state of the world.</p>
<ul>
<li>How can we use our inferences of the world to act in it?</li>
</ul>
</aside>
</section>
<section id="expected-utility-maximisation" class="slide level2">
<h2>Expected Utility Maximisation</h2>
<p><span class="math display">\[ a^* = arg \max_a \int p(x | y) \cdot U(a, x) dy \]</span></p>
<ul>
<li>Utility function <span class="math inline">\(U(x, a)\)</span> encodes our own preferences</li>
<li>Choose the action that maximises utility!</li>
</ul>
<aside class="notes">
<ul>
<li>Formalize the decision problem as a game against nature.</li>
<li>In this game, nature picks a state <span class="math inline">\(x\)</span> unknown to us, and then generates an observation <span class="math inline">\(y\)</span> which we get to see.</li>
<li>We then have to make a decision, that is, we have to choose an action <span class="math inline">\(a\)</span>.</li>
<li>Finally we have a utility function <span class="math inline">\(U(x, a)\)</span>, which measures how compatible our action <span class="math inline">\(a\)</span> and nature’s hidden state <span class="math inline">\(x\)</span> is with our own preferences.</li>
<li>Essence of what we mean by rational behaviour.</li>
</ul>
</aside>
</section>
<section id="ideal-observer-analysis" class="slide level2">
<h2>Ideal-Observer Analysis</h2>
<p>Derive a theoretically optimal model on how to perform a given task.</p>
<p><img src="./assets/generative-model.svg" alt="generative-model" width="70%"/></p>
<aside class="notes">
<ul>
<li>Optimality is to be understood in a statistical sense referring to a physical limit of information processing.</li>
<li>Does not refer to a complete absence of errors</li>
<li>Are humans optimal?</li>
</ul>
</aside>
</section>
<section id="perceptual-decision-making" class="slide level2">
<h2>Perceptual Decision Making</h2>
<p>In simple perceptual decision tasks, humans perform close to optimal. <a href="https://www.nature.com/articles/415429a"> <img src="./assets/reference-ernst.svg" alt="reference-ernst" height="200" style="display:block;margin-left:auto;margin-right: auto;"/> </a> <a href="https://www.nature.com/articles/nature02169"> <img src="./assets/reference-körding.svg" alt="reference-körding" height="200" style="display:block;margin-left:auto;margin-right: auto;"/> </a></p>
<aside class="notes">
<ul>
<li><a href="https://www.nature.com/articles/415429a">Humans integrate visual and haptic information in a statistically optimal fashion</a></li>
<li><a href="https://www.nature.com/articles/nature02169">Bayesian integration in sensorimotor learning</a></li>
<li><a href="https://doi.org/10.1007/s00221-004-2128-2">Feeling what you hear: auditory signals can modulate tactile tap perception</a></li>
</ul>
</aside>
</section></section>
<section id="monty-hall-problem" class="title-slide slide level1">
<h1>Monty Hall Problem</h1>
<p><img src="./assets/monty-hall.svg" alt="monty-hall" width="70%"/></p>
<aside class="notes">
In complex tasks the situation is less clear. - The optimal model might be computationally intractable - Humans are shown to be irrational (as we have seen in the previous talk) - Decision theory assumes a passive environment; it no longer applies when other agents enter - Causal Decision Theory &amp; Game Theory
</aside>
</section>

<section>
<section id="process-models" class="title-slide slide level1" data-background="#7BAB8B">
<h1 data-background="#7BAB8B">Process Models</h1>

</section>
<section id="marrs-levels-of-analysis" class="slide level2">
<h2>Marr’s Levels of Analysis</h2>
<p><img src="./assets/marr-levels.svg" alt="marr-levels" width="70%"/></p>
<aside class="notes">
<p>At what level of abstraction should we start to model the brain?</p>
<ol type="1">
<li>Computational level: What does the system do (e.g.: what problems does it solve or overcome)</li>
<li>Representational level: How does the system do what it does? What representations does it use and what processes does it employ to build and manipulate them</li>
<li>Implementational level: How is the system physically realised (neural structures, activities)</li>
</ol>
<ul>
<li>Reductionism: A complex system can be described as the sum of its parts.</li>
<li>Constructivism: We can only understand the constituents of the system if we have a higher level model that gives meaning to these parts.</li>
<li>Model-dependent Realism: We can only know about “reality” through models that explain observations by connecting with rules and concepts.</li>
</ul>
</aside>
</section>
<section id="artificial-neural-networks" class="slide level2">
<h2>Artificial Neural Networks</h2>
<p>Study mathematical models of the brain.</p>
<p><a href="https://playground.tensorflow.org"> <img src="./assets/neural-network.svg" alt="neural-network" width="60%"/> </a></p>
</section>
<section id="reinforcement-learning" class="slide level2">
<h2>Reinforcement Learning</h2>
<p>Let artificial agents solve real tasks.</p>
<p><a href="https://www.nature.com/articles/s41586-019-1924-6"> <img src="./assets/agent-environment.svg" alt="agent-environment" width="70%"/> </a></p>
</section></section>
    </div>
  </div>

  <script src="./reveal.js/dist/reveal.js"></script>

  // reveal.js plugins
  <script src="./reveal.js/plugin/notes/notes.js"></script>
  <script src="./reveal.js/plugin/search/search.js"></script>
  <script src="./reveal.js/plugin/zoom/zoom.js"></script>
  <script src="./reveal.js/plugin/math/math.js"></script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
        // Display controls in the bottom right corner
        controls: true,
        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,
        // Display the page number of the current slide
        slideNumber: true,
        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,
        // Push each slide change to the browser history
        history: true,
        // Global override for preloading lazy-loaded iframes
        // - null: Iframes with data-src AND data-preload will be loaded when within
        //   the viewDistance, iframes with only data-src will be loaded when visible
        // - true: All iframes with data-src will be loaded when within the viewDistance
        // - false: All iframes with data-src will be loaded only when visible
        preloadIframes: true,
        // Factor of the display size that should remain empty around the content
        margin: 0.1,
        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [
          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    </body>
</html>
